% vim: tw=70
\documentclass[10pt, a4paper]{article}
\usepackage{lrec2006}
\usepackage{graphicx}

% \usepackage[utf8x]{inputenc}
% \usepackage{times}
% \usepackage{url}
% \usepackage[small,bf]{caption}
% \usepackage{latexsym}
\usepackage{hyperref}

\newcommand{\ana}[1]{\texttt{#1}}
\newcommand{\f}[1]{`#1'}
\newcommand{\tool}[1]{\texttt{#1}}


\title{FST Intersection: Ending Dictionary Redundancy in Apertium} % TITLE TODO ugh

\name{Author1, Author2, Author3}

\address{ Affiliation1, Affiliation2, Affiliation3 \\
               Address1, Address2, Address3 \\
               author1@xxx.yy, author2@zzz.edu, author3@hhh.com\\}

\abstract{
  A Finite State Transducer (FST) used as an analyser, whose output is
  input to another FST, may have entries that don't pass through the
  second FST. We describe the development of a tool to \emph{trim}
  such entries in the \tool{lttoolbox} package used in the Apertium
  machine translation platform.
}

\begin{document}

\maketitleabstract

\section{Introduction and background}

Apertium \cite{forcada2011afp} is a rule-based machine translation
platform, where the data and tools are released under a Free and Open
Source license (primarily GNU GPL). Apertium translators use Finite
State Transducers (FST's) for morphological analysis, bilingual
dictionary lookup and generation of surface forms; most language
pairs\footnote{A \emph{language pair} is a set of resources to
  translate between a certain set of languages in Apertium, e.g.
  Basque↔Spanish.} created with Apertium use the \tool{lttoolbox}
FST library for compiling XML dictionaries into binary FST's and for
processing text with such FST's.

\subsection{The Apertium pipeline}
Translation with Apertium works as a pipeline, where each
\emph{module} processes some text and feeds its output as input to the
next module. First, a surface form like \f{fishes} passes through the
\textbf{analyser} FST module, giving a set of analyses like
\ana{fish.n.pl/fish.vblex.pres}, or, if it is unknown, simply
\ana{*fishes}. Tokenisation is done during analysis, letting the FST
decide in a left-right longest match fashion which words are tokens.
The analyser is technically the union of several FST's, each marked
for whether they contain entries which are tokenised in the regular
way (like regular words), or entries that may separate other tokens,
like punctuation. Anything that has an analysis is a token, and any
other sequence consisting of letters of the \texttt{alphabet} of the
analyser is an unknown word token. Anything else can separate tokens.

After analysis, one or more \textbf{disambiguation} modules select
which of the analyses is the correct one. The \textbf{pretransfer}
module does some minor formal changes to do with multiwords.

Then a disambiguated analysis like \ana{fish.n.pl} passes through the
\textbf{bilingual} FST. Using English→Norwegian as an example, we
would get \ana{fisk.n.m.pl} if the bilingual FST had a matching entry,
or simply \ana{@fish.n.pl} if it was unknown in that dictionary. So a
known entry may get changes to both lemma (\ana{fish}→\ana{fisk}) and tags
(\ana{n.pl}→\ana{n.m.pl}) by the bilingual FST. When processing input to
the bilingual FST, it is enough that the \emph{prefix} of the tag
sequence matches, so a bilingual dictionary writer can specify that
\ana{fish.n} goes to \ana{fisk.n.m} and not bother with specifying all
inflectional tags like number, definiteness, tense, and so on.

The output of the bilingual FST is then passed to the
\textbf{structural transfer} module (which may change word order,
ensure determiner agreement, etc.), and finally a \textbf{generator}
FST which turns analyses like \ana{fisk.n.m.pl} into forms like
\f{fiskar}. Generation is the reverse of analysis; the dictionary
which was compiled into a generator for Norwegian can also be used as
an analyser for Norwegian, by switching the compilation direction.

A major feature of the \tool{lttoolbox} FST package is the support
for multiwords and compounds. A \textbf{lexical unit} may be a simple
noun like \f{fish}, or a space-separated word like \f{hairy frogfish}
(which will be analysed as one token, but otherwise have no formal
differences from other words), or a multiword with inner inflection
like \f{takes out} (analysed as \ana{take.vblex.pri.p3.sg\# out} and
then turned into \ana{take\# out.vblex.pri.p3.sg} before bilingual
dictionary lookup), or a token which is actually two words which
should be separated before bilingual dictionary lookup, like
\f{they'll} (analysed as \ana{prpers.prn.subj.p3.mf.pl+will.vaux.inf}
and then split into \ana{prpers.prn.subj.p3.mf.pl} and \ana{will.vaux.inf}
before bilingual dictionary lookup), or a combination of these three
multiword types. 

A word that can form a compound with words to the right has a
\f{hidden} tag compound-only-L, and a word that is able to be a
right-side of a compound or a word on its own has a tag compound-R.
These hidden tags are not shown in the analysis output, but used by
the FST processor. If the noun form \f{frog} is tagged compound-only-L
and \f{fishes} is tagged compound-R, the \tool{lttoolbox} FST
processor will analyse \f{frogfishes} as a single compound token
(unless it was already in the dictionary as an explicit token), which
is split into two tokens before bilingual dictionary lookup (so the
full compound does not need to be specified in either dictionary).

\subsection{The Problem: Redundant data}

Ideally, when a monolingual dictionary for, say, English is created,
that dictionary would be available for reuse unaltered (or with only
bug fixes and additions) in all language pairs where one of the
languages is English. Unfortunately, that has not been the case in
Apertium until recently.

If a word is in the analyser, but not in the bilingual translation
dictionary, certain difficulties arise. As the example above showed,
if \f{fishes} were unknown to both dictionaries, the output would be
\ana{*fishes}, while if it were unknown to only the second, the output
would be \ana{@fish}. Given \f{*fishes}, a post-editor who knows both
languages can immediately see what the original was, while the
half-translated \ana{@fish} hides the number information in the source
text. Removing features like number, definiteness or tense can skew
meaning.  But it gets worse: Some languages inflect verbs for
\emph{negation}, where the half-translated lemma would hide the fact
that the meaning is negative.\footnote{For simple cases like this, a
    workaround is to carry surface form information throughout the
    pipeline, but this fails with multiwords (described below) and
    compounds, which are heavily used in many Apertium language
    pairs.}

And, as mentioned above, a word not known to the bilingual FST may not
have its tags translated (or translated correctly) either; when the
transfer module tries to use the half-translated tags to determine
agreement, the \emph{context} of the half-translated word may have its
meaning skewed as well.

Trying to write transfer rules to deal with half-translated tags also
\emph{increases the complexity of transfer rules}. For example, if any
noun can be missing its gender, that's one more exception to all rules
that apply gender agreement (as well as any feature that interacts with
gender).

Finally, there are issues with tokenisation and multiwords.
Multiwords in Apertium are entries in the dictionaries that may
consist of what would otherwise be several tokens. As an example, say
you have \f{take} and \f{out} listed in your English dictionary, and
they translate fine in isolation. Now, for Catalan we want to
translate the phrasal verb \f{take out} into a single word \f{treure},
so we list it as a \emph{multiword with inner inflection} in the
English dictionary. This makes any occurrence of forms of \f{take out}
get a single-token multiword analysis, e.g. \f{takes out} gets the
analysis \ana{take.vblex.pri.p3.sg\# out}. But then the whole multiword
\emph{has} to be in the bilingual dictionary if it is to be
translated. If another language pair using the same English dictionary
has both \f{take} and \f{out} in its bilingual dictionary, but not the
multiword, the individual words in isolation may be translated, but
the whole string together will not be translated.

Due to these issues, most language pairs in Apertium have a separate
copy of each monolingual dictionary, manually \emph{trimmed} to match
the entries of the bilingual dictionary; so in the example above, if
\f{take out} did not make sense to have in the bilingual dictionary,
it would be removed from the copy of the monolingual dictionary. This
of course leads to a lot of redundancy and duplicated effort; as an
example, there are currently (as of SVN revision 49929) twelve Spanish
monolingual dictionaries in stable (SVN trunk) language pairs, with
sizes varying from 36798 lines to 204447 lines.

The lack of shared monolingual dictionaries also means that other
monolingual resources, like disambiguator data, is not shared, since
the effort of copying files is less than the effort of letting one
module depend on another for little gain.

\subsection{A Solution: Intersection}

However, there is a way around these troubles. Finite state machines
can be intersected with one another to produce a new finite state
machine. In the case of the Apertium transducers, what we want is to
intersect the output (or \textbf{right}) side of the full analyser
with the input (or \textbf{left}) side of the bilingual FST, producing
a \emph{trimmed} FST. We call this \emph{trimming}.

Some recent language pairs in Apertium use the alternative FST
framework HFST \cite{linden2011hfst}\footnote{Partly due to available
data in that formalism, partly due to features missing from
\tool{lttoolbox} like \emph{flag diacritics}.}. Using HFST, one can
create a "prefixed" version of the bilingual FST, this is is the
concatenation of the bilingual FST and the regular expression
\texttt{.*}, ie. match any symbol zero or more times. Then the command
\tool{hfst-compose-intersect} on the analyser and the prefixed FST
creates the FST where only those paths of the analyser remain where
the right side of the analyser match the left side of the bilingual
FST. The prefixing is necessary since, as mentioned above, the
bilingual dictionary is underspecified for inflectional tags such as
definiteness, and so on.

The HFST solution works, but is missing many of the Apertium-specific
features such as different types of tokenisation FST's, and it does
not handle the fact that multiwords may split or change format before
bilingual dictionary lookup. Also, HFST represents compounds with an
optional transition from the end of the noun to the beginning of the
noun dictionary -- so if \ana{frog.n} and \ana{fish.n} were in the
analyser, but \ana{fish.n} were missing from the bilingual FST,
\ana{frog.n+fish.n} would remain in the trimmed FST since the prefix
matches. In addition, using HFST in language pairs whose data are all
in \tool{lttoolbox} format would introduce a new dependency.

Thus we decided to create a new tool in \tool{lttoolbox} called
\tool{lt-trim}, that trims an analyser using a bilingual FST

\section{Discussion}
\section*{Acknowledgements}
Part of the development was funded by the Google
Code-In\footnote{\href{https://code.google.com/gci/}{https://code.google.com/gci/}} programme.

\bibliographystyle{lrec2006}
\bibliography{apertium}

\end{document}
